{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If you lost points on the last checkpoint you can get them back by responding to TA/IA feedback**  \n",
    "\n",
    "Update/change the relevant sections where you lost those points, make sure you respond on GitHub Issues to your TA/IA to call their attention to the changes you made here.\n",
    "\n",
    "Please update your Timeline... no battle plan survives contact with the enemy, so make sure we understand how your plans have changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Data Checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Names\n",
    "\n",
    "- Ant Man\n",
    "- Hulk\n",
    "- Iron Man\n",
    "- Thor\n",
    "- Wasp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include a general introduction to your topic\n",
    "- Include explanation of what work has been done previously\n",
    "- Include citations or links to previous work\n",
    "\n",
    "This section will present the background and context of your topic and question in a few paragraphs. Include a general introduction to your topic and then describe what information you currently know about the topic after doing your initial research. Include references to other projects who have asked similar questions or approached similar problems. Explain what others have learned in their projects.\n",
    "\n",
    "Find some relevant prior work, and reference those sources, summarizing what each did and what they learned. Even if you think you have a totally novel question, find the most similar prior work that you can and discuss how it relates to your project.\n",
    "\n",
    "References can be research publications, but they need not be. Blogs, GitHub repositories, company websites, etc., are all viable references if they are relevant to your project. It must be clear which information comes from which references. (2-3 paragraphs, including at least 2 references)\n",
    "\n",
    " **Use inline citation through HTML footnotes to specify which references support which statements** \n",
    "\n",
    "For example: After government genocide in the 20th century, real birds were replaced with surveillance drones designed to look just like birds.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) Use a minimum of 2 or 3 citations, but we prefer more.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) You need enough to fully explain and back up important facts. \n",
    "\n",
    "Note that if you click a footnote number in the paragraph above it will transport you to the proper entry in the footnotes list below.  And if you click the ^ in the footnote entry, it will return you to the place in the main text where the footnote is made.\n",
    "\n",
    "To understand the HTML here, `<a name=\"#...\"> </a>` is a tag that allows you produce a named reference for a given location.  Markdown has the construciton `[text with hyperlink](#named reference)` that will produce a clickable link that transports you the named reference.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Lorenz, T. (9 Dec 2021) Birds Aren’t Real, or Are They? Inside a Gen Z Conspiracy Theory. *The New York Times*. https://www.nytimes.com/2021/12/09/technology/birds-arent-real-gen-z-misinformation.html \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Also refs should be important to the background, not some randomly chosen vaguely related stuff. Include a web link if possible in refs as above.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- Include your team's hypothesis\n",
    "- Ensure that this hypothesis is clear to readers\n",
    "- Explain why you think this will be the outcome (what was your thinking?)\n",
    "\n",
    "What is your main hypothesis/predictions about what the answer to your question is? Briefly explain your thinking. (2-3 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "1. Explain what the **ideal** dataset you would want to answer this question. (This should include: What variables? How many observations? Who/what/how would these data be collected? How would these data be stored/organized?)<br>\n",
    "* Our ideal dataset would be a dataset that includes measures for a region's GDP, environmental degradation, homelessness, and crime rates. While measures for GDP, homelessness, and crime rates are straightforward, environmental degradation is not as clear. Thus we can use tools provided by the state such as CalEnviroScreen 4.0 to act as measures for a region's environmental degradation. Unemployment data can be found from the California Employment Development Department, crime data from OpenJustice led by the California Department of Justice, and U.S. Census for some population data. Alternatively, we have information from San Diego for data regarding specific regions within San Diego county. This can be obtained directly from the San Diego County database. All of this data is available in usable forms (csv file, Microsoft Excel spreadsheet, etc.) through government websites. We would convert our files into pandas dataframes, which we would then merge into one dataframe that includes the data that we want. That is, the ideal dataset would be organized by it's observations of main regions in San Diego county, where the variables will be the region's income/capita, environmental degradation, homelessness, and crime rates. \n",
    "\n",
    "* Our ideal number of observations include our variables from all cities or regions in San Diego County across multiple years with the ideal span being about 5 years. This would look like about 18 cities with (ask dean for year span) Looking at the data we have already found our time span can vary. Our found environmental data isn't tracked by year so we need to search for a dataset that is. Our income data spans from 2012 to 2024 for all cities in San Diego county. Our unemployment data doesn't include specific cities in San Diego county so we need to find data that does. Our crime data accounts for all the cities wanted and spans 2009 to 2023.\n",
    "\n",
    "1. Search for potential **real** datasets that could provide you with something useful for this project.  You do not have to find every piece of data you will use, but you do need to have demonstrated some idea that (a) this data is gettable and (b) that this data may be different from what your ideal is.<br>\n",
    "\n",
    "* <u>**Environmental degradation**</u> data: https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-40<br>\n",
    "\n",
    "* **San Diego Median Income/Capita, Crime Rates, Unemployment info, based on specific regions in San Diego** <br>\n",
    "https://data.sandiegocounty.gov/Live-Well-San-Diego/Live-Well-/San-Diego-Database/wsyp-5xpf/about_data <br> \n",
    "\n",
    "* <u>**Unemployment.. Less than Ideal**</u> <br>\n",
    "Unemployment rate for California (as a whole):  https://labormarketinfo.edd.ca.gov/geography/california-statewide.html <br>\n",
    "Unemployment rate for California (as counties): https://labormarketinfo.edd.ca.gov/geography/lmi-by-county.html <br>\n",
    "* <u>Crime</u> <br>\n",
    "Crime rates broken down into total crime, violent crime, and property crime rates for cities/regions in San Diego county: https://data.sandiegocounty.gov/Safety/SANDAG-Crime-Data/486f-q228/data_preview <br>\n",
    "\n",
    "\n",
    "* All these sites have data that's not only obtainable but also easily processes because they are kept in Excel files. Excel files are csv files which can be easily turned into pandas dataframes. Of course, these sites contain more data than we need in our project, so tidying will be necessary. Moreover, we may choose a focus on specific types of crimes, such as violent crimes versus misdemeanors, or we may choose to look at all crime as a whole. \n",
    "\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Dataset Name:\n",
    "  - Link to the dataset:\n",
    "  - Number of observations:\n",
    "  - Number of variables:\n",
    "- Dataset #2 \n",
    "  - Dataset Name: Crime Rate Dataset\n",
    "  - Link to the datasets: \n",
    "  - https://dof.ca.gov/forecasting/demographics/estimates/ (for population)\n",
    "  - https://openjustice.doj.ca.gov/data (for crime count)\n",
    "  - Number of observations: 28591 (for crime), 1770 (for population)\n",
    "  - Number of variables: 70 (for crime), 3 (for population)\n",
    "  - Description: We plan to look at **Violent_sum**, **Property_sum** within the crime count dataset & **Population** within the population dataset. For both, we will look at **Year** and **County**. Both datasets contain datetime datatype for **Year**, integer datatype for **Violent_sum**, **Property_sum**, & **Population**, and string datatype for **County**, but can contain undefined values which we will use **0** as a proxy. \n",
    "  - We plan to use `.strip()` for removing empty spaces, `pd.to_datetime()` for converting **Year** to an integer datatype, `.split()` for removing redundant words like '*County*' in 'Alameda *County*', `.astype()` to explicity convert our data to integer, `.melt()` to reshape the population dataframe to a long format, `.drop()` for unecessary columns, `.rename()` for making consistent columns before merge, and `.merge()` to get the complete Crime Rate Dataset.\n",
    "- etc\n",
    "\n",
    "Now write 2 - 5 sentences describing each dataset here. Include a short description of the important variables in the dataset; what the metrics and datatypes are, what concepts they may be proxies for. Include information about how you would need to wrangle/clean/preprocess the dataset\n",
    "\n",
    "If you plan to use multiple datasets, add a few sentences about how you plan to combine these datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #1 (use name instead of number here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/SANDAG_Crime_Data_20250502.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/SANDAG_Crime_Data_20250502.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m cities \u001b[38;5;241m=\u001b[39m df[(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJurisdiction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCalifornia\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m&\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJurisdiction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m      3\u001b[0m cities\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/SANDAG_Crime_Data_20250502.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/SANDAG_Crime_Data_20250502.csv')\n",
    "cities = df[(df['Jurisdiction'] != 'California') & (df['Jurisdiction'] != 'United States')]\n",
    "cities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>County</th>\n",
       "      <th>Violent_sum</th>\n",
       "      <th>Property_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>2001</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>9422</td>\n",
       "      <td>65891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>2001</td>\n",
       "      <td>Alpine</td>\n",
       "      <td>8</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>2001</td>\n",
       "      <td>Amador</td>\n",
       "      <td>141</td>\n",
       "      <td>887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>2001</td>\n",
       "      <td>Butte</td>\n",
       "      <td>629</td>\n",
       "      <td>6893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>2001</td>\n",
       "      <td>Calaveras</td>\n",
       "      <td>128</td>\n",
       "      <td>1013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tulare</td>\n",
       "      <td>2481</td>\n",
       "      <td>9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2258</th>\n",
       "      <td>2023</td>\n",
       "      <td>Tuolumne</td>\n",
       "      <td>369</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2259</th>\n",
       "      <td>2023</td>\n",
       "      <td>Ventura</td>\n",
       "      <td>2411</td>\n",
       "      <td>11071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2260</th>\n",
       "      <td>2023</td>\n",
       "      <td>Yolo</td>\n",
       "      <td>561</td>\n",
       "      <td>4968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2261</th>\n",
       "      <td>2023</td>\n",
       "      <td>Yuba</td>\n",
       "      <td>334</td>\n",
       "      <td>828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1334 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Year     County  Violent_sum  Property_sum\n",
       "928   2001    Alameda         9422         65891\n",
       "929   2001     Alpine            8           121\n",
       "930   2001     Amador          141           887\n",
       "931   2001      Butte          629          6893\n",
       "932   2001  Calaveras          128          1013\n",
       "...    ...        ...          ...           ...\n",
       "2257  2023     Tulare         2481          9535\n",
       "2258  2023   Tuolumne          369           522\n",
       "2259  2023    Ventura         2411         11071\n",
       "2260  2023       Yolo          561          4968\n",
       "2261  2023       Yuba          334           828\n",
       "\n",
       "[1334 rows x 4 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading number of crime data\n",
    "# Cleaning up data\n",
    "crime_num_df = pd.read_csv(\n",
    "    './Datasets/Crime/Crimes_and_Clearances_with_arson-1985-2023.csv', \n",
    "    dtype=object)\n",
    "crime_num_df = crime_num_df.drop(columns='NCICCode')\n",
    "crime_num_df.replace(' ', 0, inplace=True)\n",
    "crime_num_df.replace(np.nan, 0, inplace=True)\n",
    "for col in crime_num_df.columns: \n",
    "    if(col == 'County' or col == 'NCICCode'): \n",
    "        continue \n",
    "    crime_num_df[col] = crime_num_df[col].astype(int)\n",
    "crime_num_df = crime_num_df[['Year', 'County', 'Violent_sum', 'Property_sum']].groupby(['Year', 'County']).sum()\n",
    "crime_num_df = crime_num_df.reset_index()\n",
    "crime_num_df = crime_num_df[crime_num_df['Year'] >= 2001]\n",
    "\n",
    "# Removing 'County'\n",
    "crime_num_df['Year'] = crime_num_df['Year'].astype(object)\n",
    "name = crime_num_df.get('County').str.split().str[:-1]\n",
    "crime_num_df['County'] = name.apply(' '.join)\n",
    "\n",
    "crime_num_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>2000</td>\n",
       "      <td>1443939.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpine</td>\n",
       "      <td>2000</td>\n",
       "      <td>1208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amador</td>\n",
       "      <td>2000</td>\n",
       "      <td>35100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Butte</td>\n",
       "      <td>2000</td>\n",
       "      <td>203171.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calaveras</td>\n",
       "      <td>2000</td>\n",
       "      <td>40554.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>Tuolumne</td>\n",
       "      <td>2025</td>\n",
       "      <td>54357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>Ventura</td>\n",
       "      <td>2025</td>\n",
       "      <td>829005.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Yolo</td>\n",
       "      <td>2025</td>\n",
       "      <td>225433.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>Yuba</td>\n",
       "      <td>2025</td>\n",
       "      <td>85023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>State Total</td>\n",
       "      <td>2025</td>\n",
       "      <td>39529101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1770 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          County  Year  Population\n",
       "0        Alameda  2000   1443939.0\n",
       "1         Alpine  2000      1208.0\n",
       "2         Amador  2000     35100.0\n",
       "3          Butte  2000    203171.0\n",
       "4      Calaveras  2000     40554.0\n",
       "..           ...   ...         ...\n",
       "349     Tuolumne  2025     54357.0\n",
       "350      Ventura  2025    829005.0\n",
       "351         Yolo  2025    225433.0\n",
       "352         Yuba  2025     85023.0\n",
       "353  State Total  2025  39529101.0\n",
       "\n",
       "[1770 rows x 3 columns]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Population Data for 2000-2010\n",
    "p1_df = pd.read_excel(\n",
    "    './Datasets/Census/E4_2000-2010_Report_Final_EOC_000.xlsx',\n",
    "    sheet_name=1,skiprows=3)\n",
    "p1_df.dropna(how='all', inplace=True)\n",
    "p1_df = pd.melt(\n",
    "    p1_df, id_vars='COUNTY',\n",
    "    var_name='Year', \n",
    "    value_name='Population')\n",
    "p1_df['COUNTY'] = p1_df.get('COUNTY').str.strip()\n",
    "\n",
    "# Load Population Data for 2010-2020\n",
    "p2_df = pd.read_excel(\n",
    "    './Datasets/Census/E-4_2010-2020-Internet-Version.xlsx',\n",
    "    sheet_name=1, skiprows=1)\n",
    "p2_df.drop(columns=['Column1', 'Column2'], inplace=True)\n",
    "p2_df = pd.melt(p2_df, id_vars='COUNTY', var_name='Year',\n",
    "    value_name='Population')\n",
    "p2_df.dropna(how='all', inplace=True)\n",
    "p2_df['COUNTY'] = p2_df.get('COUNTY').str.strip()\n",
    "p2_df.get('Year').apply(pd.to_datetime)\n",
    "\n",
    "# Load Population Data 2020-2025\n",
    "p3_df = pd.read_excel(\n",
    "    './Datasets/Census/E-4_2025_InternetVersion.xlsx',\n",
    "    sheet_name=1, skiprows=2)\n",
    "p3_df = p3_df.iloc[0:59]\n",
    "p3_df = pd.melt(p3_df, id_vars='County', var_name='Year',\n",
    "    value_name='Population')\n",
    "p3_df['County'] = p3_df.get('County').str.strip()\n",
    "p3_df = p3_df.rename(columns={'County': \"COUNTY\"})\n",
    "p3_df\n",
    "\n",
    "# Merge Population Data From 2000-2025 + Clean Up Data\n",
    "pop_df = pd.concat([p1_df, p2_df, p3_df])\n",
    "pop_df['Year'] = pop_df.get('Year').apply(pd.to_datetime).dt.year\n",
    "pop_df.rename(columns={'COUNTY':'County'}, inplace=True)\n",
    "pop_df['Year'] = pop_df['Year'].astype(object)\n",
    "pop_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>County</th>\n",
       "      <th>Year</th>\n",
       "      <th>Population</th>\n",
       "      <th>Violent_sum</th>\n",
       "      <th>Property_sum</th>\n",
       "      <th>Violent_perc</th>\n",
       "      <th>Property_perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alameda</td>\n",
       "      <td>2001</td>\n",
       "      <td>1457185.0</td>\n",
       "      <td>9422</td>\n",
       "      <td>65891</td>\n",
       "      <td>0.006466</td>\n",
       "      <td>0.045218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alpine</td>\n",
       "      <td>2001</td>\n",
       "      <td>1220.0</td>\n",
       "      <td>8</td>\n",
       "      <td>121</td>\n",
       "      <td>0.006557</td>\n",
       "      <td>0.09918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amador</td>\n",
       "      <td>2001</td>\n",
       "      <td>35495.0</td>\n",
       "      <td>141</td>\n",
       "      <td>887</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.024989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Butte</td>\n",
       "      <td>2001</td>\n",
       "      <td>204591.0</td>\n",
       "      <td>629</td>\n",
       "      <td>6893</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>0.033692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Calaveras</td>\n",
       "      <td>2001</td>\n",
       "      <td>41042.0</td>\n",
       "      <td>128</td>\n",
       "      <td>1013</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.024682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      County  Year Population  Violent_sum  Property_sum Violent_perc  \\\n",
       "0    Alameda  2001  1457185.0         9422         65891     0.006466   \n",
       "1     Alpine  2001     1220.0            8           121     0.006557   \n",
       "2     Amador  2001    35495.0          141           887     0.003972   \n",
       "3      Butte  2001   204591.0          629          6893     0.003074   \n",
       "4  Calaveras  2001    41042.0          128          1013     0.003119   \n",
       "\n",
       "  Property_perc  \n",
       "0      0.045218  \n",
       "1       0.09918  \n",
       "2      0.024989  \n",
       "3      0.033692  \n",
       "4      0.024682  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge Population Dataset With Crime Number Dataset\n",
    "crime_rate_df = pop_df.merge(crime_num_df, on=['Year', 'County'])\n",
    "\n",
    "# Calculate crime rate percentages\n",
    "crime_rate_df['Violent_perc'] = (crime_rate_df['Violent_sum'])/(crime_rate_df['Population'])\n",
    "crime_rate_df['Property_perc'] = (crime_rate_df['Property_sum'])/(crime_rate_df['Population'])\n",
    "\n",
    "crime_rate_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1566, 7)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime_rate_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?\n",
    "\n",
    "When it comes to dealing with ethics for our project, there may be potential region bias in the data available since it may be the case that there are missing regions that are underrepresented in the available government datasets listed above. Additionally, since we are mostly sampling from local government datasets there may be bias as we are not including other datasets that aren't federal which may pose as a confounding variable as not all crime, homelessness, and unemployment may be accounted for if not reported to the government. Though a confounding variable, the data collected from websites such as openjustice.doj.ca.gov permits the public usage of the data from their webiste, noting that their website public data is made sure to not include personal information of minors and or use copyrighted material. Addtionally, the data that we plan on scraping from census.gov already has personal identifying information removed and is publicly available for use as well, protecting personal privacy. Furthermore, there may be bias in our statistical analyses when it comes to looking at the rate of crime rate for a specific high income cities which can bias our interpretations of the data. Addtionally, we are focusing our analyses on San Diego County which can potentially be more expensive of a county to live in compared to other counties in California. Additionally, counties like San Diego will have different economies which can potentially skew our analyses as San Diego may not be able to provide enough economic diversity to tailor to all counties in California. <br>\n",
    "\n",
    "To address these issues, we will explore what missing regions there are in the datasets and why they are underrepresented. That way, we can transparently report these reasons as factors that can impact our intrepretation when we analyze our data. For instance, findings that indicate a strong relationship between our variables and crime rate may not be applicable to rural areas. Furthermore, regarding data collections, data regarding crime, homelessness, and umemployment are tracked by the government, but this is something out of our scope of responsibilities. Instead, we can acknowledge that a false negative may be consistent with this underrepresentation when interpreting the relationship between our variables and crime. In this understanding, we may not be able to say for certain that findings of 'no relationship' is true. \n",
    "\n",
    "Our aim for this project is to find a more accurate measure for region's well-being, i.e. environment and economic factors may be considered, and how we can use this for a predictor model that can assist in assessing regions for their levels of crime. This project can be scaled for use in determining how the government can improve their allocation of resources to improve a region's well-being. However, because of bias in our project, our findings may only be applicable to regions similar to San Diego. That is, underrepresented regions should not be observed with our lens. Despite this bias, misuse or misinterpretation of our finding can be misleading and improperly measure a region's well-being. This can lead to reduction in select regions' aid from the government that can adversely affect them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Expectations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Read over the [COGS108 Team Policies](https://github.com/COGS108/Projects/blob/master/COGS108_TeamPolicies.md) individually. Then, include your group’s expectations of one another for successful completion of your COGS108 project below. Discuss and agree on what all of your expectations are. Discuss how your team will communicate throughout the quarter and consider how you will communicate respectfully should conflicts arise. By including each member’s name above and by adding their name to the submission, you are indicating that you have read the COGS108 Team Policies, accept your team’s expectations below, and have every intention to fulfill them. These expectations are for your team’s use and benefit — they won’t be graded for their details.\n",
    "\n",
    "* *Team Expectation 1*\n",
    "* *Team Expectation 2*\n",
    "* *Team Expecation 3*\n",
    "* ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Timeline Proposal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify your team's specific project timeline. An example timeline has been provided. Changes the dates, times, names, and details to fit your group's plan.\n",
    "\n",
    "If you think you will need any special resources or training outside what we have covered in COGS 108 to solve your problem, then your proposal should state these clearly. For example, if you have selected a problem that involves implementing multiple neural networks, please state this so we can make sure you know what you’re doing and so we can point you to resources you will need to implement your project. Note that you are not required to use outside methods.\n",
    "\n",
    "\n",
    "\n",
    "| Meeting Date  | Meeting Time| Completed Before Meeting  | Discuss at Meeting |\n",
    "|---|---|---|---|\n",
    "| 1/20  |  1 PM | Read & Think about COGS 108 expectations; brainstorm topics/questions  | Determine best form of communication; Discuss and decide on final project topic; discuss hypothesis; begin background research | \n",
    "| 1/26  |  10 AM |  Do background research on topic | Discuss ideal dataset(s) and ethics; draft project proposal | \n",
    "| 2/1  | 10 AM  | Edit, finalize, and submit proposal; Search for datasets  | Discuss Wrangling and possible analytical approaches; Assign group members to lead each specific part   |\n",
    "| 2/14  | 6 PM  | Import & Wrangle Data (Ant Man); EDA (Hulk) | Review/Edit wrangling/EDA; Discuss Analysis Plan   |\n",
    "| 2/23  | 12 PM  | Finalize wrangling/EDA; Begin Analysis (Iron Man; Thor) | Discuss/edit Analysis; Complete project check-in |\n",
    "| 3/13  | 12 PM  | Complete analysis; Draft results/conclusion/discussion (Wasp)| Discuss/edit full project |\n",
    "| 3/20  | Before 11:59 PM  | NA | Turn in Final Project & Group Project Surveys |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
